---
title: "p8105_hw6_yz4433"
author: "Yifei Zhao"
date: "2022-11-29"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(httr)
library(RCurl)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

To obtain a distribution for $\hat{r}^2$, we'll follow basically the same procedure we used for regression coefficients: draw bootstrap samples; the a model to each; extract the value I'm concerned with; and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `broom::glance` to produce `r.squared` values. 

```{r weather_df, cache = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  modelr::bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with $r^2$, this distribution is somewhat skewed and has some outliers. 

The point of this is not to say you should always use the bootstrap -- it's possible to establish "large sample" distributions for strange parameters / values / summaries in a lot of cases, and those are great to have. But it is helpful to know that there's a way to do inference even in tough cases. 

## Problem 2
### manipulate data
```{r}
hcdata =  read_csv(file = "./data/homicide-data.csv", show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(city_state = paste(city,',',state)) %>% 
  mutate(group = ifelse((disposition == 'Closed by arrest'), 1, 0)) %>%
  filter(!city_state %in% c("Dallas , TX", "Phoenix , AZ", "Kansas City , MO", "Tulsa , AL")) %>% 
  filter(victim_race %in% c("Black", "White")) %>% 
  filter(victim_age != 'Unknown')
```

### glm for Baltimore
```{r}
baldata = hcdata %>% 
  filter(city_state == "Baltimore , MD")

glmbal = glm(group ~ victim_age + victim_sex + victim_race, data = baldata, family = binomial)
```

```{r}
glmres = glmbal %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate)) %>% 
  mutate(ci_low = data.frame(exp(confint.default(glmbal, level = 0.95)))[[1]], ci_high = data.frame(exp(confint.default(glmbal, level = 0.95)))[[2]]) %>% 
  filter(term == "victim_sexMale") %>% 
  select(-5:-1)
glmres
```

### glm for each city
```{r}
ct = hcdata %>%
  group_by(city_state)
list_ct = group_split(ct)
```

```{r}
orci = function(x) {
  glmi = glm(group ~ victim_age + victim_sex + victim_race, data = x, family = binomial)
  glmi %>% 
    broom::tidy() %>% 
    mutate(city_state = x[[1,13]]) %>% 
    mutate(or = exp(estimate)) %>% 
    mutate(ci_low = data.frame(exp(confint.default(glmi, level = 0.95)))[[1]], ci_high = data.frame(exp(confint.default(glmi, level = 0.95)))[[2]]) %>% 
    filter(term == "victim_sexMale") %>%
    select(-5:-1) %>% 
    data.frame()
}
```

```{r}
output = map_dfr(list_ct, orci)
output
```

### plot of ORs and CIs for each city
```{r}
p = ggplot(output, aes(x = reorder(city_state, or), y = or, fill = city_state)) +
  geom_bar(stat = "identity", color = "black", position = position_dodge()) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = .2, position = position_dodge(.9)) +
  theme(legend.position = "none") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "city name", y = "estimated ORs", title = "ORs and CIs for each city")
print(p)
```

